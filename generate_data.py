import numpy as np


class kArmedBandit(object):
    """
    Specifies a k-armed bandit problem
    
    The agent has to choose from k different actions.
    Taking an action yields a numeric reward specified by a stationary probability distribution.
    """

    def __init__(self, k=10):
        """ Constructor """

        # sample action values from gaussian with mean 0 and standard deviation 1
        self.q_star = np.random.randn(k)

    def step(self, action):
        """
        Take one step following the given action.
        
        Parameters
        ----------
           @action: action id (integer in [0, k[)
        
        Returns
        -------
            the reward for taking this action.
        """
        Ri = self.q_star[action] + np.random.randn() * 2

        return Ri


class IncrementalSampleAverageMethod(object):
    """
    Incremental Implemenation of Sample Average Method
    
    Parameters
    ----------
        @k: number of possible actions (integer)
        @epsilon: probability for selecting a random action (float in [0, 1])
    """

    def __init__(self, k=10, epsilon=0.0):
        """ Constructor """
        # TODO
        self.k = k
        self.epsilon = epsilon
        self.Q = np.zeros(k)
        self.N = np.zeros(k)

    def choose_action(self):
        """ Action selection """

        if np.random.uniform() < self.epsilon:
            At = np.random.choice(self.k)
        else:
            At = np.argmax(self.Q)

        return At

    def update_estimates(self, action, reward):
        """ update action value estimate """

        self.N[action] += 1
        self.Q[action] = self.Q[action] + (1 / self.N[action]) * (reward - self.Q[action])


def generate_data(n_actions=20, n_steps=20000, epsilon=0.1, seed=10):
    np.random.seed(seed)

    bandit_instance = kArmedBandit(k=n_actions)

    rewards = np.zeros((n_steps))

    value_func = np.zeros((n_steps, n_actions))

    agent = IncrementalSampleAverageMethod(n_actions, epsilon)

    for step in range(n_steps):
        value_func[step, :] = agent.Q

        action = agent.choose_action()

        reward = bandit_instance.step(action)

        agent.update_estimates(action, reward)

        rewards[step] = reward

    return {'value_func': value_func, 'rewards': rewards, 'optimal_vf': bandit_instance.q_star}
